{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1F9XxSN05aDEQQ4Rm2cMI80wUJWDqhTfP",
      "authorship_tag": "ABX9TyNi8cXcOct/YebQk056CfWV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDankloff/Cluster-Bias-Disco/blob/main/baf_exploratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/MDankloff/Cluster-Bias-Disco.git\n",
        "#!cd Cluster-Bias-Disco/"
      ],
      "metadata": {
        "id": "ZVAg2oanH7dq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! cd '/content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvLZyz_LKAEF",
        "outputId": "e49f684b-f338-4ec2-e4f1-0bc08431d304"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import lightgbm as lgbm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import glob\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "FGODOIzkMzL0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/parquet data'\n",
        "\n",
        "extension = \"parquet\" #for smaller \"parquet\" depending on the downloaded file\n",
        "data_paths = glob.glob(f\"{base_path}/*.{extension}\")\n",
        "\n",
        "def read_dataset(path, ext = extension):\n",
        "    if ext == \"csv\":\n",
        "      return pd.read_csv(path)\n",
        "    elif ext == \"parquet\":\n",
        "      return pd.read_parquet(path)\n",
        "    else:\n",
        "      raise ValueError(f\"Unsupported file extension: {ext}\")\n",
        "\n",
        "# Extract variant name from the file path (without the extension)\n",
        "def get_variant(path):\n",
        "    return os.path.basename(path).split(\".\")[0]\n",
        "\n",
        "# Dictionary comprehension to read all CSV files into a dictionary of DataFrames\n",
        "dataframes = {\n",
        "    get_variant(path): read_dataset(path) for path in data_paths\n",
        "}\n",
        "print(f\"Loaded datasets: {list(dataframes.keys())}\")\n",
        "\n",
        "datasets_paths = {\n",
        "    \"Base\": base_path + \"/Base.parquet\", # sampled to best represent original dataset\n",
        "    \"Variant I\": base_path + \"/Variant I.parquet\", # higher group size disparity than base - reducing the size of the minority group from approx 20 - 10% of the dataset\n",
        "    \"Variant II\": base_path + \"/Variant II.parquet\", # higher prevalence disparity than base - one group has 5 x the fraud detection rate of the other while group sizes are equal\n",
        "    \"Variant III\": base_path + \"/Variant III.parquet\", # better separability for one of the groups -\n",
        "    \"Variant IV\": base_path + \"/Variant IV.parquet\", # higher prevalence disparity in train\n",
        "    \"Variant V\": base_path + \"/Variant V.parquet\", # better separability in train for one of the groups\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wBiCCQTfpHP",
        "outputId": "6900a738-9745-4faa-83e3-85f0aa2ba474"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded datasets: ['Base', 'Variant I', 'Variant II', 'Variant III', 'Variant IV', 'Variant V']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename datasets\n",
        "base = dataframes['Base']\n",
        "variant1 = dataframes['Variant I']\n",
        "variant2 = dataframes['Variant II']\n",
        "variant3 = dataframes['Variant III']\n",
        "variant4 = dataframes['Variant IV']\n",
        "variant5 = dataframes['Variant V']"
      ],
      "metadata": {
        "id": "o78df7oDh7Zb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# directory containing the model files\n",
        "model_dir = '/content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant'\n",
        "\n",
        "# Get list of all model files in the directory\n",
        "model_files = glob.glob(os.path.join(model_dir, '*.pkl'))\n",
        "\n",
        "# Dictionary to store loaded models\n",
        "models = {}\n",
        "\n",
        "# Load all models from the directory and save them to the dictionary\n",
        "for model_file in model_files:\n",
        "    # Load the model\n",
        "    with open(model_file, 'rb') as f:\n",
        "        model = joblib.load(f)\n",
        "\n",
        "    # Extract the model name from the file path (without extension)\n",
        "    model_name = os.path.basename(model_file).split('.')[0]\n",
        "\n",
        "    # Add the model to the dictionary\n",
        "    models[model_name] = model\n",
        "\n",
        "    # Optional: Save the model back (though it seems redundant here)\n",
        "    save_path = os.path.join(model_dir, f'{model_name}.pkl')\n",
        "    joblib.dump(model, save_path)\n",
        "\n",
        "    print(f\"Model '{model_name}' loaded and saved to: {save_path}\")\n",
        "\n",
        "# Example: Accessing specific models\n",
        "modelb1 = models.get(\"model_Base_4\")  # Replace key with the desired model name\n",
        "modelb2 = models.get(\"model_Base_7\")\n",
        "modelv11 = models.get(\"model_Variant I_4\")\n",
        "modelv12 = models.get(\"model_Variant I_7\")\n",
        "modelv21 = models.get(\"model_Variant II_4\")\n",
        "modelv22 = models.get(\"model_Variant II_7\")\n",
        "modelv31 = models.get(\"model_Variant III_4\")\n",
        "modelv32 = models.get(\"model_Variant III_7\")\n",
        "modelv41 = models.get(\"model_Variant IV_4\")\n",
        "modelv42 = models.get(\"model_Variant IV_7\")\n",
        "modelv51 = models.get(\"model_Variant V_4\")\n",
        "modelv52 = models.get(\"model_Variant V_7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3xBfZhIITLa",
        "outputId": "c63bec97-a189-4b6a-cfc2-92d64ca6adf7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 'model_Base_4' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Base_4.pkl\n",
            "Model 'model_Variant III_7' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Variant III_7.pkl\n",
            "Model 'model_Variant II_4' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Variant II_4.pkl\n",
            "Model 'model_Variant I_4' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Variant I_4.pkl\n",
            "Model 'model_Base_7' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Base_7.pkl\n",
            "Model 'model_Variant II_7' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Variant II_7.pkl\n",
            "Model 'model_Variant IV_4' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Variant IV_4.pkl\n",
            "Model 'model_Variant I_7' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Variant I_7.pkl\n",
            "Model 'model_Variant III_4' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Variant III_4.pkl\n",
            "Model 'model_Variant V_4' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Variant V_4.pkl\n",
            "Model 'model_Variant IV_7' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Variant IV_7.pkl\n",
            "Model 'model_Variant V_7' loaded and saved to: /content/drive/MyDrive/Mirthe_Supervision /Paper#3/BAF/Best 2 models per variant/model_Variant V_7.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "variant1.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On3ng0FUA5Qc",
        "outputId": "9b410ff6-f0a4-49f7-8b99-8ea5b2e2936b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 32 columns):\n",
            " #   Column                            Non-Null Count    Dtype  \n",
            "---  ------                            --------------    -----  \n",
            " 0   fraud_bool                        1000000 non-null  int64  \n",
            " 1   income                            1000000 non-null  float64\n",
            " 2   name_email_similarity             1000000 non-null  float64\n",
            " 3   prev_address_months_count         1000000 non-null  int64  \n",
            " 4   current_address_months_count      1000000 non-null  int64  \n",
            " 5   customer_age                      1000000 non-null  int64  \n",
            " 6   days_since_request                1000000 non-null  float64\n",
            " 7   intended_balcon_amount            1000000 non-null  float64\n",
            " 8   payment_type                      1000000 non-null  object \n",
            " 9   zip_count_4w                      1000000 non-null  int64  \n",
            " 10  velocity_6h                       1000000 non-null  float64\n",
            " 11  velocity_24h                      1000000 non-null  float64\n",
            " 12  velocity_4w                       1000000 non-null  float64\n",
            " 13  bank_branch_count_8w              1000000 non-null  int64  \n",
            " 14  date_of_birth_distinct_emails_4w  1000000 non-null  int64  \n",
            " 15  employment_status                 1000000 non-null  object \n",
            " 16  credit_risk_score                 1000000 non-null  int64  \n",
            " 17  email_is_free                     1000000 non-null  int64  \n",
            " 18  housing_status                    1000000 non-null  object \n",
            " 19  phone_home_valid                  1000000 non-null  int64  \n",
            " 20  phone_mobile_valid                1000000 non-null  int64  \n",
            " 21  bank_months_count                 1000000 non-null  int64  \n",
            " 22  has_other_cards                   1000000 non-null  int64  \n",
            " 23  proposed_credit_limit             1000000 non-null  float64\n",
            " 24  foreign_request                   1000000 non-null  int64  \n",
            " 25  source                            1000000 non-null  object \n",
            " 26  session_length_in_minutes         1000000 non-null  float64\n",
            " 27  device_os                         1000000 non-null  object \n",
            " 28  keep_alive_session                1000000 non-null  int64  \n",
            " 29  device_distinct_emails_8w         1000000 non-null  int64  \n",
            " 30  device_fraud_count                1000000 non-null  int64  \n",
            " 31  month                             1000000 non-null  int64  \n",
            "dtypes: float64(9), int64(18), object(5)\n",
            "memory usage: 244.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = variant1.drop(['fraud_bool'], axis=1)\n",
        "Y = variant1['fraud_bool']"
      ],
      "metadata": {
        "id": "PY8a2RFSOAGi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Try out for modelv11, modelv12\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.7, shuffle = True, stratify = Y)\n",
        "\n",
        "model = models.get(\"model_Variant I_4_model\")\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "Yhat = model.predict(X_test)\n",
        "len(Yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "owbh-rQ7Fc4d",
        "outputId": "4078b26a-6a3a-4b24-92fe-07af44a0c88e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'fit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-be981246d5aa>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_Variant I_4\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mYhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'fit'"
          ]
        }
      ]
    },
    {
      "source": [
        "#Try out for modelv11, modelv12\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.7, shuffle = True, stratify = Y)\n",
        "\n",
        "# The original line was: model = models[\"model_Variant I_4\"]\n",
        "# This likely accesses a dictionary of model metrics instead of the model itself.\n",
        "# Assuming your models are stored with keys like \"model_Variant I_4_model\" (or similar),\n",
        "# you should access the actual model object.\n",
        "\n",
        "# Assuming that the model name follows the pattern \"model_Variant I_4_model\"\n",
        "model = models.get(\"model_Variant I_4_model\")\n",
        "# If the above fails, you need to find the correct key for the model\n",
        "# Print out the keys of the \"models\" dictionary to see available model names\n",
        "print(models.keys())\n",
        "\n",
        "\n",
        "# Alternatively, if the model is stored within a nested dictionary under a key like 'model', try:\n",
        "# model = models[\"model_Variant I_4\"][\"model\"]\n",
        "\n",
        "# Ensure 'model' now holds the actual model object before proceeding\n",
        "if model is not None:\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    Yhat = model.predict(X_test)\n",
        "    len(Yhat)\n",
        "else:\n",
        "    print(\"Model not found. Please check the key used to access the model.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6lu89BNPO6V",
        "outputId": "8fbb1082-33ce-4254-9f02-32d8162efa18"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['model_Base_4', 'model_Variant III_7', 'model_Variant II_4', 'model_Variant I_4', 'model_Base_7', 'model_Variant II_7', 'model_Variant IV_4', 'model_Variant I_7', 'model_Variant III_4', 'model_Variant V_4', 'model_Variant IV_7', 'model_Variant V_7'])\n",
            "Model not found. Please check the key used to access the model.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#Try out for modelv11, modelv12\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.7, shuffle = True, stratify = Y)\n",
        "\n",
        "model_data = models.get(\"model_Variant I_4\") # Get the dictionary containing the model and other data\n",
        "if model_data is not None and \"model\" in model_data:\n",
        "    model = model_data[\"model\"] # Access the model object from within the dictionary\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    Yhat = model.predict(X_test)\n",
        "    len(Yhat)\n",
        "else:\n",
        "    print(\"Model not found or structured differently. Check the contents of 'models'.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwjYK14yPhiu",
        "outputId": "7f2f5e5e-e320-4d23-cb0d-91d8cad8258b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model not found or structured differently. Check the contents of 'models'.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import pprint # Import pprint for better formatting\n",
        "\n",
        "# Print the contents of \"model_Variant I_4\" for inspection\n",
        "pprint.pprint([\"/content/model_Base_top_0.pkl\"])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Wum5iN2Pn-5",
        "outputId": "062f84f0-cdf9-47df-87be-55a6228ade74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/model_Base_top_0.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(models[\"model_Variant V_7\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bepxh4b2QEfW",
        "outputId": "9838e66b-a851-4681-e31a-46411d4de975"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fpr Older': 0.08309047555967677,\n",
            " 'fpr Younger': 0.015993436855103352,\n",
            " 'recall': 0.33295625942684764,\n",
            " 'recall Older': 0.582962962962963,\n",
            " 'recall Younger': 0.07296466973886329}\n"
          ]
        }
      ]
    }
  ]
}
