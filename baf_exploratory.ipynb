{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1F9XxSN05aDEQQ4Rm2cMI80wUJWDqhTfP",
      "authorship_tag": "ABX9TyMlT9C3uTlMMQ3EWAlbL67d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDankloff/Cluster-Bias-Disco/blob/main/baf_exploratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/feedzai/bank-account-fraud.git\n",
        "!git clone https://github.com/MDankloff/Cluster-Bias-Disco.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVAg2oanH7dq",
        "outputId": "ef873d76-65ab-4aaa-bb75-e1e7d8334081"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bank-account-fraud'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 110 (delta 54), reused 64 (delta 23), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (110/110), 1.13 MiB | 8.70 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "Cloning into 'Cluster-Bias-Disco'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 54 (delta 28), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (54/54), 446.32 KiB | 5.01 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "i-MFm9TyVNpH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import lightgbm as lgbm\n",
        "import yaml              # Read hyperparameter space configuration\n",
        "import glob\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder # Categorical encoding for LGBM models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "\n",
        "#from aequitas.group import Group                # Fairness metrics\n",
        "#from random_search import RandomValueTrial, suggest_callable_hyperparams  # Random search wrapper methods\n",
        "\n",
        "import yaml\n",
        "\n",
        "# If the file is within a subdirectory, for example, named \"config\":\n",
        "with open(\"/content/lightgbm_hyperparameter_space.yaml\", \"r\") as file:\n",
        "    # Remove the 'Loader' argument\n",
        "    hyperparam_space = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvLZyz_LKAEF",
        "outputId": "26388fe1-9f67-480c-b6e9-63094bc446eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/Mirthe Supervision Map /Paper 3: FC Bias Disco/BAF/parquet data'\n",
        "\n",
        "extension = \"parquet\" #for smaller \"parquet\" depending on the downloaded file\n",
        "data_paths = glob.glob(f\"{base_path}/*.{extension}\")\n",
        "\n",
        "def read_dataset(path, ext = extension):\n",
        "    if ext == \"csv\":\n",
        "      return pd.read_csv(path)\n",
        "    elif ext == \"parquet\":\n",
        "      return pd.read_parquet(path)\n",
        "    else:\n",
        "      raise ValueError(f\"Unsupported file extension: {ext}\")\n",
        "\n",
        "# Extract variant name from the file path (without the extension)\n",
        "def get_variant(path):\n",
        "    return os.path.basename(path).split(\".\")[0]\n",
        "\n",
        "# Dictionary comprehension to read all CSV files into a dictionary of DataFrames\n",
        "dataframes = {\n",
        "    get_variant(path): read_dataset(path) for path in data_paths\n",
        "}\n",
        "print(f\"Loaded datasets: {list(dataframes.keys())}\")\n",
        "\n",
        "datasets_paths = {\n",
        "    \"Base\": base_path + \"/Base.parquet\", # sampled to best represent original dataset\n",
        "    \"Variant I\": base_path + \"/Variant I.parquet\", # higher group size disparity than base - reducing the size of the minority group from approx 20 - 10% of the dataset\n",
        "    \"Variant II\": base_path + \"/Variant II.parquet\", # higher prevalence disparity than base - one group has 5 x the fraud detection rate of the other while group sizes are equal\n",
        "    \"Variant III\": base_path + \"/Variant III.parquet\", # better separability for one of the groups -\n",
        "    \"Variant IV\": base_path + \"/Variant IV.parquet\", # higher prevalence disparity in train\n",
        "    \"Variant V\": base_path + \"/Variant V.parquet\", # better separability in train for one of the groups\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wBiCCQTfpHP",
        "outputId": "51d23346-6f0d-4cf2-fca9-8808c0d1b6ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded datasets: ['Base', 'Variant I', 'Variant II', 'Variant III', 'Variant IV', 'Variant V']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base = dataframes['Base']\n",
        "variant1 = dataframes['Variant I']\n",
        "variant2 = dataframes['Variant II']\n",
        "variant3 = dataframes['Variant III']\n",
        "variant4 = dataframes['Variant IV']\n",
        "variant5 = dataframes['Variant V']"
      ],
      "metadata": {
        "id": "o78df7oDh7Zb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''categorical_features = [\n",
        "    \"payment_type\",\n",
        "    \"employment_status\",\n",
        "    \"housing_status\",\n",
        "    \"source\",\n",
        "    \"device_os\",\n",
        "]'''"
      ],
      "metadata": {
        "id": "esMUowAyVRl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variant1.info()\n",
        "variant1['fraud_bool'].unique()\n",
        "variant1['payment_type'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2IWM2JDR-gs",
        "outputId": "e9ea555e-c352-4e46-b616-8f1f226c6291"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 32 columns):\n",
            " #   Column                            Non-Null Count    Dtype  \n",
            "---  ------                            --------------    -----  \n",
            " 0   fraud_bool                        1000000 non-null  int64  \n",
            " 1   income                            1000000 non-null  float64\n",
            " 2   name_email_similarity             1000000 non-null  float64\n",
            " 3   prev_address_months_count         1000000 non-null  int64  \n",
            " 4   current_address_months_count      1000000 non-null  int64  \n",
            " 5   customer_age                      1000000 non-null  int64  \n",
            " 6   days_since_request                1000000 non-null  float64\n",
            " 7   intended_balcon_amount            1000000 non-null  float64\n",
            " 8   payment_type                      1000000 non-null  object \n",
            " 9   zip_count_4w                      1000000 non-null  int64  \n",
            " 10  velocity_6h                       1000000 non-null  float64\n",
            " 11  velocity_24h                      1000000 non-null  float64\n",
            " 12  velocity_4w                       1000000 non-null  float64\n",
            " 13  bank_branch_count_8w              1000000 non-null  int64  \n",
            " 14  date_of_birth_distinct_emails_4w  1000000 non-null  int64  \n",
            " 15  employment_status                 1000000 non-null  object \n",
            " 16  credit_risk_score                 1000000 non-null  int64  \n",
            " 17  email_is_free                     1000000 non-null  int64  \n",
            " 18  housing_status                    1000000 non-null  object \n",
            " 19  phone_home_valid                  1000000 non-null  int64  \n",
            " 20  phone_mobile_valid                1000000 non-null  int64  \n",
            " 21  bank_months_count                 1000000 non-null  int64  \n",
            " 22  has_other_cards                   1000000 non-null  int64  \n",
            " 23  proposed_credit_limit             1000000 non-null  float64\n",
            " 24  foreign_request                   1000000 non-null  int64  \n",
            " 25  source                            1000000 non-null  object \n",
            " 26  session_length_in_minutes         1000000 non-null  float64\n",
            " 27  device_os                         1000000 non-null  object \n",
            " 28  keep_alive_session                1000000 non-null  int64  \n",
            " 29  device_distinct_emails_8w         1000000 non-null  int64  \n",
            " 30  device_fraud_count                1000000 non-null  int64  \n",
            " 31  month                             1000000 non-null  int64  \n",
            "dtypes: float64(9), int64(18), object(5)\n",
            "memory usage: 244.1+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['AC', 'AA', 'AB', 'AD', 'AE'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_base1 = \"/content/model_Base_4.pkl\"\n",
        "model_base2 = \"/content/model_Base_7.pkl\"\n",
        "model_variant1_1 = \"/content/model_Variant I_4.pkl\"\n",
        "model_variant1_2 = \"/content/model_Variant I_7.pkl\"\n",
        "\n",
        "modelb1 = joblib.load(model_base1)\n",
        "modelb2 = joblib.load(model_base2)\n",
        "modelv11 = joblib.load(model_variant1_1)\n",
        "modelv12 = joblib.load(model_variant1_2)\n"
      ],
      "metadata": {
        "id": "CUXk9TZQPcOA"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}