{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDankloff/Cluster-Bias-Disco/blob/main/empirical_results_feedzai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# coding=utf-8\n",
        "#\n",
        "# The copyright of this file belongs to Feedzai. The file cannot be\n",
        "# reproduced in whole or in part, stored in a retrieval system,\n",
        "# transmitted in any form, or by any means electronic, mechanical,\n",
        "# photocopying, or otherwise, without the prior permission of the owner.\n",
        "#\n",
        "# (c) 2022 Feedzai, Strictly Confidential"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5S98_JGFkYc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Dhn3ya4IeEWR",
        "outputId": "95d0997e-6c08-4bd8-c8fd-2468a69ca8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth==2.27.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.27.0)\n",
            "Requirement already satisfied: ipykernel==5.5.6 in /usr/local/lib/python3.10/dist-packages (from google-colab) (5.5.6)\n",
            "Requirement already satisfied: ipyparallel==8.8.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (8.8.0)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.5.5 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.5.5)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.2.2)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.32.3)\n",
            "Requirement already satisfied: tornado==6.3.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.3.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google-colab) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google-colab) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google-colab) (4.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (6.1.12)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (0.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=18 in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (24.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ipyparallel==8.8.0->google-colab) (4.66.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython==7.34.0->google-colab)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (3.1.4)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->google-colab) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->google-colab) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->google-colab) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->google-colab) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->google-colab) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->google-colab) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3->google-colab) (2024.8.30)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.5->google-colab) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google-colab) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (24.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google-colab) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google-colab) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.27.0->google-colab) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->ipyparallel==8.8.0->google-colab) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook==6.5.5->google-colab) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.5->google-colab) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook==6.5.5->google-colab) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.2.2)\n",
            "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aequitas\n",
        "!pip install dask[dataframe]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "_dUIOxxQko7b",
        "outputId": "62869f19-bc30-451c-dcd5-2ba9bb446b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aequitas\n",
            "  Downloading aequitas-1.0.0-3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting matplotlib>=3.7.5 (from aequitas)\n",
            "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from aequitas) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.10/dist-packages (from aequitas) (6.0.2)\n",
            "Collecting seaborn>=0.13.2 (from aequitas)\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting altair>=5.4.0 (from aequitas)\n",
            "  Downloading altair-5.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting millify>=0.1.1 (from aequitas)\n",
            "  Downloading millify-0.1.1.tar.gz (1.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from aequitas) (1.13.1)\n",
            "Collecting optuna>=3.6.1 (from aequitas)\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aif360>=0.6.1 (from aequitas)\n",
            "  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lightgbm>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from aequitas) (4.5.0)\n",
            "Collecting fairgbm>=0.9.14 (from aequitas)\n",
            "  Downloading fairgbm-0.9.14-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting fairlearn>=0.10.0 (from aequitas)\n",
            "  Downloading fairlearn-0.10.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting hydra-core>=1.3.2 (from aequitas)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting hyperparameter-tuning>=0.3.1 (from aequitas)\n",
            "  Downloading hyperparameter_tuning-0.3.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting validators>=0.33.0 (from aequitas)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from aequitas) (1.26.4)\n",
            "Collecting fastparquet>=2024.2.0 (from aequitas)\n",
            "  Downloading fastparquet-2024.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.10/dist-packages (from aequitas) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from aequitas) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360>=0.6.1->aequitas) (1.5.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair>=5.4.0->aequitas) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=5.4.0->aequitas) (4.23.0)\n",
            "Collecting narwhals>=1.5.2 (from altair>=5.4.0->aequitas)\n",
            "  Downloading narwhals-1.9.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from altair>=5.4.0->aequitas) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from altair>=5.4.0->aequitas) (4.12.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from fairgbm>=0.9.14->aequitas) (0.44.0)\n",
            "Collecting cramjam>=2.3 (from fastparquet>=2024.2.0->aequitas)\n",
            "  Downloading cramjam-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet>=2024.2.0->aequitas) (2024.6.1)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->aequitas)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->aequitas)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting schema (from hyperparameter-tuning>=0.3.1->aequitas)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.5->aequitas) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.5->aequitas) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.5->aequitas) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.5->aequitas) (1.4.7)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.5->aequitas) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.5->aequitas) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.5->aequitas) (2.8.2)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.6.1->aequitas)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna>=3.6.1->aequitas)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.6.1->aequitas) (2.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna>=3.6.1->aequitas) (4.66.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->aequitas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->aequitas) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.3->aequitas) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.3->aequitas) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.3->aequitas) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.3->aequitas) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->aequitas) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->aequitas) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->aequitas) (3.3)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.6.1->aequitas)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=5.4.0->aequitas) (0.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->aequitas) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360>=0.6.1->aequitas) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360>=0.6.1->aequitas) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.6.1->aequitas) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair>=5.4.0->aequitas) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.4.0->aequitas) (1.3.0)\n",
            "Downloading aequitas-1.0.0-3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aif360-0.6.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading altair-5.4.1-py3-none-any.whl (658 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.1/658.1 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fairgbm-0.9.14-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fairlearn-0.10.0-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.1/234.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastparquet-2024.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hyperparameter_tuning-0.3.2-py3-none-any.whl (26 kB)\n",
            "Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cramjam-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.9.1-py3-none-any.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.8/180.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, millify\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=3be8785e8c756ab3e972673a482512bc583e2e0ad03dea5da7149ecc1103b162\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for millify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for millify: filename=millify-0.1.1-py3-none-any.whl size=1844 sha256=7cf814258d37394d1a2e4982610ffa7a65cbbdd6ab4e8adb8e2c00375b3aceea\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/8f/53/2759feac2e247ce89c1165c3ff12d484de7714a875ea3464f0\n",
            "Successfully built antlr4-python3-runtime millify\n",
            "Installing collected packages: schema, millify, antlr4-python3-runtime, validators, omegaconf, narwhals, Mako, cramjam, colorlog, matplotlib, hydra-core, alembic, seaborn, optuna, fastparquet, fairlearn, fairgbm, aif360, hyperparameter-tuning, altair, aequitas\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.13.1\n",
            "    Uninstalling seaborn-0.13.1:\n",
            "      Successfully uninstalled seaborn-0.13.1\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 4.2.2\n",
            "    Uninstalling altair-4.2.2:\n",
            "      Successfully uninstalled altair-4.2.2\n",
            "Successfully installed Mako-1.3.5 aequitas-1.0.0 aif360-0.6.1 alembic-1.13.3 altair-5.4.1 antlr4-python3-runtime-4.9.3 colorlog-6.8.2 cramjam-2.8.4 fairgbm-0.9.14 fairlearn-0.10.0 fastparquet-2024.5.0 hydra-core-1.3.2 hyperparameter-tuning-0.3.2 matplotlib-3.9.2 millify-0.1.1 narwhals-1.9.1 omegaconf-2.3.0 optuna-4.0.0 schema-0.7.7 seaborn-0.13.2 validators-0.34.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "139795ec221547c5898f3caea4b4f5b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.8.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.4.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.2)\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[dataframe])\n",
            "  Downloading dask_expr-1.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask_expr-1.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyarrow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (16.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.20.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n",
            "Downloading dask_expr-1.1.10-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dask-expr\n",
            "Successfully installed dask-expr-1.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRCud3_eodiO",
        "outputId": "a1679e24-cba7-4853-f05f-ff0a662fe468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgbm  # Tested ML method\n",
        "import numpy as np       # Random number generation\n",
        "import seaborn as sns    # Plotting library\n",
        "import pandas as pd      # Read/write data\n",
        "import yaml              # Read hyperparameter space configuration\n",
        "import glob\n",
        "import os\n",
        "from aequitas.group import Group                # Fairness metrics\n",
        "from matplotlib import pyplot as plt            # Plotting method\n",
        "from sklearn.preprocessing import LabelEncoder  # Categorical encoding for LGBM models\n",
        "from sklearn import metrics                     # ROC metrics\n",
        "\n",
        "from random_search import RandomValueTrial, suggest_callable_hyperparams  # Random search wrapper methods"
      ],
      "metadata": {
        "id": "Pok0NdA9km5u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gtA3zRoekYc8"
      },
      "outputs": [],
      "source": [
        "# Read hyperparameter space for the LGBM Models, expected structure is presented bellow\n",
        "with open(\"lightgbm_hyperparameter_space.yaml\", \"r\") as file:\n",
        "    hyperparam_space = yaml.load(file, Loader=yaml.FullLoader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/Mirthe Supervision Map /Paper 3a: FC Bias Disco/BAF'\n",
        "extension = \"csv\"  # or \"parquet\", depending on the downloaded file\n",
        "\n",
        "# Find all files with the specified extension\n",
        "data_paths = glob.glob(f\"{base_path}/*.{extension}\")\n",
        "\n",
        "def read_dataset(path, ext=extension):\n",
        "    if ext == \"csv\":\n",
        "        return pd.read_csv(path)\n",
        "    elif ext == \"parquet\":\n",
        "        return pd.read_parquet(path)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file extension: {ext}\")\n",
        "\n",
        "# Extract variant name from the file path (without the extension)\n",
        "def get_variant(path):\n",
        "    return os.path.basename(path).split(\".\")[0]\n",
        "\n",
        "# Dictionary comprehension to read all datasets into a dictionary of DataFrames\n",
        "dataframes = {\n",
        "    get_variant(path): read_dataset(path) for path in data_paths\n",
        "}\n",
        "print(f\"Loaded datasets: {list(dataframes.keys())}\")\n",
        "\n",
        "# Manual paths in case specific datasets need to be loaded individually\n",
        "datasets_paths = {\n",
        "    \"Base\": base_path + \"/Base.csv\",\n",
        "    \"Variant I\": base_path + \"/Variant I.csv\",\n",
        "    \"Variant II\": base_path + \"/Variant II.csv\",\n",
        "    \"Variant III\": base_path + \"/Variant III.csv\",\n",
        "    \"Variant IV\": base_path + \"/Variant IV.csv\",\n",
        "    \"Variant V\": base_path + \"/Variant V.csv\",\n",
        "}\n"
      ],
      "metadata": {
        "id": "TGDgbkuHkTLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9f2c9d-b857-4f85-ebad-9e39d60f3ced"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded datasets: ['Base', 'Variant I', 'Variant II', 'Variant III', 'Variant IV', 'Variant V']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = {key: read_dataset(path) for key, path in datasets_paths.items()}"
      ],
      "metadata": {
        "id": "oJknxhi7idGM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "68ltek01kYc9"
      },
      "outputs": [],
      "source": [
        "# The expected structure is the following:\n",
        "hyperparam_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zQe9vXfqkYc9"
      },
      "outputs": [],
      "source": [
        "# Testing a random search suggestion:\n",
        "trial = RandomValueTrial(seed=1)\n",
        "suggest_callable_hyperparams(trial, hyperparam_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zyj206nEkYc_"
      },
      "outputs": [],
      "source": [
        "# Define the label field and categorical columns.\n",
        "label = \"fraud_bool\"\n",
        "\n",
        "categorical_features = [\n",
        "    \"payment_type\",\n",
        "    \"employment_status\",\n",
        "    \"housing_status\",\n",
        "    \"source\",\n",
        "    \"device_os\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wJ_KGrVYkYdA"
      },
      "outputs": [],
      "source": [
        "# Create the train and test sets. Shuffle data with `sample` method.\n",
        "# The split was done by month. The first 6 months as the train, the last 2 months as test.\n",
        "train_dfs = {key: df[df[\"month\"]<6].sample(frac=1, replace=False) for key, df in datasets.items()}\n",
        "test_dfs = {key: df[df[\"month\"]>=6].sample(frac=1, replace=False) for key, df in datasets.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LuQub5vMkYdA"
      },
      "outputs": [],
      "source": [
        "# Encode the categorical variables in the datasets to integers.\n",
        "# This is expected by LGBM (or columns with the `categorical` data type).\n",
        "\n",
        "for name in datasets.keys():  # For each dataset in the suite\n",
        "    train = train_dfs[name]\n",
        "    test = test_dfs[name]\n",
        "\n",
        "    for feat in categorical_features:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(train[feat])  # Fit an encoder to the train set.\n",
        "        train[feat] = encoder.transform(train[feat])  # Transform train set.\n",
        "        test[feat] = encoder.transform(test[feat])    # Transform test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hf3Mj-ffkYdA"
      },
      "outputs": [],
      "source": [
        "# Cell with train loop for hyperparameter tuning of an LGBM classifier across variant datasets\n",
        "\n",
        "# Define number of trials in Random search\n",
        "n_trials=100\n",
        "# Random state for sampling seeds\n",
        "np.random.seed(42)\n",
        "# Seeds for the random search sampling algorithm\n",
        "seeds = np.random.choice(list(range(1_000_000)), size=n_trials, replace=False)\n",
        "\n",
        "# Variable to store the results for each run\n",
        "runs = {}\n",
        "\n",
        "for trial in range(n_trials):\n",
        "    seed = seeds[trial]\n",
        "    trial = RandomValueTrial(seed=seed)\n",
        "    # Hyperparameters for the random search trial\n",
        "    test_hyperparams = suggest_callable_hyperparams(trial, hyperparam_space)\n",
        "    #del test_hyperparams[\"classpath\"] # Remove unnecessary key in hyperparaemters\n",
        "\n",
        "    # Update list of tested hyperparameters.\n",
        "    prev_hyperparams = runs.get(\"hyperparams\", [])\n",
        "    prev_hyperparams.append(test_hyperparams)\n",
        "    runs[\"hyperparams\"] = prev_hyperparams\n",
        "\n",
        "    for dataset_name in datasets.keys():  # Run hyperparameters on all variants of datastes\n",
        "        model = lgbm.LGBMClassifier(n_jobs=10, **test_hyperparams)  # Instantiate LGBM Model\n",
        "        X_train = train_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n",
        "        y_train = train_dfs[dataset_name][\"fraud_bool\"]\n",
        "        X_test = test_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n",
        "        y_test = test_dfs[dataset_name][\"fraud_bool\"]\n",
        "        # Fit model to training data.\n",
        "        model.fit(X_train, y_train, categorical_feature=categorical_features)\n",
        "        # Obtain predictions in test data.\n",
        "        predictions = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Obtain ROC curve for the predictions.\n",
        "        fprs, tprs, thresholds = metrics.roc_curve(y_test, predictions)\n",
        "        # Obtain threshold and recall. We select 5% FPR as threshold\n",
        "        threshold = np.min(thresholds[fprs==max(fprs[fprs < 0.05])])\n",
        "        recall = np.max(tprs[fprs==max(fprs[fprs < 0.05])])\n",
        "\n",
        "        # Binarize predictions for Aequitas.\n",
        "        preds_binary = (predictions > threshold).astype(int)\n",
        "\n",
        "        # Create a dataframe with protected group column, predictions and labels.\n",
        "        # Here, we select age>=50 as threshold.\n",
        "        aequitas_df = pd.DataFrame(\n",
        "            {\n",
        "                \"age\": (X_test[\"customer_age\"]>=50).map({True: \"Older\", False: \"Younger\"}),\n",
        "                \"preds\": preds_binary,\n",
        "                \"y\": y_test.values\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Obtain FPR results for different groups.\n",
        "        g = Group()\n",
        "        aequitas_results = g.get_crosstabs(aequitas_df, attr_cols=[\"age\"], score_col=\"preds\", label_col=\"y\")[0]\n",
        "\n",
        "        # Store the results for the trained model\n",
        "        results = {}\n",
        "        results[\"recall\"] = recall\n",
        "        results[\"recall Older\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Older\"][[\"tpr\"]].values[0][0]\n",
        "        results[\"recall Younger\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Younger\"][[\"tpr\"]].values[0][0]\n",
        "        results[\"fpr Older\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Older\"][[\"fpr\"]].values[0][0]\n",
        "        results[\"fpr Younger\"] = aequitas_results[aequitas_results[\"attribute_value\"] == \"Younger\"][[\"fpr\"]].values[0][0]\n",
        "\n",
        "        # Store the results in the runs variable\n",
        "        prev_runs = runs.get(dataset_name, [])\n",
        "        prev_runs.append(results)\n",
        "        runs[dataset_name] = prev_runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WdN-4OOVkYdB"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe with the results for each model in each dataset.\n",
        "rs_results = pd.DataFrame(runs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mu15FiWBkYdB"
      },
      "outputs": [],
      "source": [
        "# Helper method to obtain the metric values for a given model.\n",
        "def get_results(results, variant, metric):\n",
        "    col = results[variant]\n",
        "    values = []\n",
        "    for idx, val in col.iteritems():\n",
        "        values.append(val[metric])\n",
        "    return values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vzQ7wfCHkYdC"
      },
      "outputs": [],
      "source": [
        "# Obtain the relevant metrics to plots from the dataframe.\n",
        "variants = list(datasets_paths.keys())\n",
        "\n",
        "plot_results = {\"Variant\": [], \"Recall\": [], \"FPR Ratio\": []}\n",
        "\n",
        "for variant in variants:\n",
        "    plot_results[\"Recall\"] += get_results(rs_results, variant, \"recall\")\n",
        "    # Obtain the FPR if both groups.\n",
        "    for fpr_younger, fpr_older in zip(get_results(rs_results, variant, \"fpr Younger\"), get_results(rs_results, variant, \"fpr Older\")):\n",
        "        # Calculate FPR ratio as higher fpr / lower fpr\n",
        "        if fpr_younger > fpr_older:\n",
        "            plot_results[\"FPR Ratio\"] += [fpr_older/fpr_younger]\n",
        "        else:\n",
        "            plot_results[\"FPR Ratio\"] += [fpr_younger/fpr_older]\n",
        "    plot_results[\"Variant\"] += [variant] * len(get_results(rs_results, variant, \"recall\"))\n",
        "\n",
        "# Create a dataframe for easier plots.\n",
        "plot_results = pd.DataFrame(plot_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qc5udDvRkYdC"
      },
      "outputs": [],
      "source": [
        "# Create a plot with the full results of the random search algorithm.\n",
        "sns.set()\n",
        "sns.set_style(\"whitegrid\", {\"grid.linestyle\": \"--\"})\n",
        "\n",
        "sns.jointplot(data=plot_results, x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\")\n",
        "plt.ylim((0,1));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5HqSd3PMkYdC"
      },
      "outputs": [],
      "source": [
        "# Create the final plot. Highlight the top models:\n",
        "top_n = 5\n",
        "top_models_base = plot_results.loc[plot_results['Variant'] == 'Base'].sort_values('Recall', ascending=False).head(top_n).index.values\n",
        "top_models = deepcopy(top_models_base)\n",
        "for i in range(1, 6):\n",
        "    top_models = np.r_[top_models, top_models_base + (100 * i)]\n",
        "\n",
        "plot_results['index'] = plot_results.index\n",
        "plot_results['is_top'] = plot_results.apply(lambda x: 1 if x['index'] in top_models else 0, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gaI6QDr7kYdC"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\", {\"grid.linestyle\": \"--\", \"grid.alpha\":0.1})\n",
        "DPI = 200\n",
        "plt.rcParams['figure.dpi'] = DPI\n",
        "plt.rcParams['figure.figsize'] = (10,5)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "\n",
        "# LEFT PLOT\n",
        "sns.scatterplot(ax=ax1, data=plot_results.loc[(~plot_results.index.isin(top_models)), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", alpha=0.2)\n",
        "sns.scatterplot(ax=ax1, data=plot_results.loc[plot_results.index.isin(top_models), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", legend=False)\n",
        "ax1.set(\n",
        "    ylim=(0,1)\n",
        ")\n",
        "\n",
        "# RIGHT PLOT\n",
        "sns.scatterplot(ax=ax2, data=plot_results.loc[(~plot_results.index.isin(top_models)) & (plot_results[\"Variant\"].isin([\"Base\", \"Type II\", \"Type V\", \"Type IV\"])), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", alpha=0.2, palette=[sns.color_palette()[0], sns.color_palette()[2], sns.color_palette()[4], sns.color_palette()[5]], legend=False)\n",
        "sns.scatterplot(ax=ax2, data=plot_results.loc[(plot_results.index.isin(top_models)) & (plot_results[\"Variant\"].isin([\"Base\", \"Type II\", \"Type V\", \"Type IV\"])), :], x=\"Recall\", y=\"FPR Ratio\", hue=\"Variant\", palette=[sns.color_palette()[0], sns.color_palette()[2], sns.color_palette()[4], sns.color_palette()[5]], legend=False)\n",
        "ax2.set(\n",
        "    ylim=(0,0.4),\n",
        "    ylabel=\"\",\n",
        "    xticks=np.arange(0.2, 0.8, 0.1),\n",
        "    yticks=np.arange(0, 0.5, 0.1),\n",
        "    xlim=(0.2, 0.6),\n",
        ")\n",
        "\n",
        "rect = plt.Rectangle((0.2, 0.004), 0.4, 0.396, facecolor=(0.1, 0.1, 0.1, 0.05), edgecolor=\"grey\", linestyle=\"-\")\n",
        "ax1.add_patch(rect)\n",
        "handles, labels = ax1.get_legend_handles_labels()\n",
        "handles = list(handles) + [rect]\n",
        "labels = list(labels) + [\"Plot on the right\"]\n",
        "ax1.legend(handles, labels, title=\"Variant\")\n",
        "\n",
        "sns.move_legend(\n",
        "    ax1,\n",
        "    loc=\"lower center\",\n",
        "    bbox_to_anchor=[1.08, -0.32],\n",
        "    ncol=7\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}